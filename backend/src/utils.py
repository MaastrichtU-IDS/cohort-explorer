import logging
from typing import Any

import curies
from rdflib import Dataset, Namespace, URIRef
from rdflib.namespace import RDF, RDFS, DC
from enum import Enum
import urllib.parse
from SPARQLWrapper import JSON, SPARQLWrapper

from src.config import settings
from src.models import Cohort, CohortVariable, VariableCategory

# Define the namespaces
ICARE = Namespace("https://w3id.org/icare4cvd/")

class OntologyNamespaces(Enum):
    CMEO = Namespace("https://w3id.org/CMEO/")
    OMOP = Namespace("http://omop.org/OMOP/")
    ATC = Namespace("http://purl.bioontology.org/ontology/ATC/")
    RXNORM = Namespace("http://purl.bioontology.org/ontology/RXNORM/")
    UCUM = Namespace("http://unitsofmeasure.org/")
    OMOP_EXT = Namespace("http://omop.org/omopextension/")
    OWL = Namespace("http://www.w3.org/2002/07/owl#")
    OBI = Namespace("http://purl.obolibrary.org/obo/obi.owl/")
    BFO = Namespace("http://purl.obolibrary.org/obo/bfo.owl/")
    STATO = Namespace("http://purl.obolibrary.org/obo/stato.owl/")
    DEFAULT_VALUE = 'Unmapped'
    SNOMEDCT = Namespace("http://purl.bioontology.org/ontology/SNOMEDCT/")
    LOINC = Namespace("http://purl.bioontology.org/ontology/LNC/") 
    RO = Namespace("http://purl.obolibrary.org/obo/ro.owl/")
    IAO = Namespace("http://purl.obolibrary.org/obo/iao.owl/")
    TIME = Namespace("http://www.w3.org/2006/time#")
    SIO = Namespace("http://semanticscience.org/ontology/sio/v1.59/sio-release.owl#")

query_endpoint = SPARQLWrapper(settings.query_endpoint)
query_endpoint.setReturnFormat(JSON)
# Set timeout to 300 seconds (5 minutes) for large queries
query_endpoint.setTimeout(300)
# Enable HTTP connection keep-alive for better performance
query_endpoint.addCustomHttpHeader("Connection", "keep-alive")

# CURIES converter docs: https://curies.readthedocs.io/en/latest/
# Using URIs from from https://bioregistry.io/
prefix_map = [
    {
        "prefix": "snomedct",
        "uri_prefix": "http://snomed.info/id/",
        "prefix_synonyms": ["snomed", "SNOMED"],
    },
    {
        "prefix": "loinc",
        "uri_prefix": "http://loinc.org/rdf/",
        "prefix_synonyms": ["LOINC"],
    },
    {
        "prefix": "icare",
        "uri_prefix": str(ICARE),
    },
    {
        "prefix": "icd10",
        "uri_prefix": "https://icd.who.int/browse10/2019/en#/",
    },
    {
        "prefix": "atc",
        "uri_prefix": "http://www.whocc.no/atc_ddd_index/?code=",
    },
    {   
        "prefix": "rxnorm",
        "uri_prefix": "https://mor.nlm.nih.gov/RxNav/search?searchBy=RXCUI&searchTerm=",
        "prefix_synonyms": ["RXNORM"]
    },
    {
        "prefix": "cdisc",
        "uri_prefix": "https://www.cdisc.org/search?search_api_fulltext="
    },
    {
        "prefix": "omop",
        "uri_prefix": "https://athena.ohdsi.org/search-terms/terms/",
        "prefix_synonyms": ["OMOP"]
    },
    {
        "prefix": "ucum",
        "uri_prefix": "http://unitsofmeasure.org/ucum/",
        "prefix_synonyms": ["UCUM"]
    }
]
curie_converter = curies.load_extended_prefix_map(prefix_map)

# Old way to do it using the predefined bioregistry:
# curie_converter = curies.get_bioregistry_converter()
# curie_converter.add_prefix("icare", str(ICARE))

# def init_graph(default_graph: str | None = None) -> Dataset:
#     """Initialize a new RDF graph for nquads with the iCARE4CVD namespace bindings."""
#     g = Dataset(store="Oxigraph", default_graph_base=default_graph)
#     g.bind("icare", ICARE)
#     g.bind("rdf", RDF)
#     g.bind("rdfs", RDFS)
#     return g

def normalize_text(text: str) -> str:
    if text is None or text == "nan" or text == "":
        return None
    text = str(text).lower().strip().replace(" ", "_").replace("/", "_").replace(":", "_").replace('[','').replace(']','')
    return urllib.parse.quote(text, safe='_-')

def init_graph(default_graph_identifier: str | None = "https://w3id.org/CMEO/graph/studies_metadata") -> Dataset:
    """Initialize a new RDF graph for nquads with the voc namespace bindings."""
    g = Dataset(store="Oxigraph")
    g.bind("cmeo", OntologyNamespaces.CMEO.value)
    g.bind("bfo", OntologyNamespaces.BFO.value)
    g.bind("obi", OntologyNamespaces.OBI.value)
    g.bind("stato", OntologyNamespaces.STATO.value)
    g.bind("rdf", RDF)
    g.bind("rdfs", RDFS)
    # g.bind("omop", OMOP)
    g.bind("dc", DC)
    # g.bind("snomed", SNOMED)
    # do we need individual bindings for each ontology?
         # g.bind("snomed", SNOMED)
        # g.bind("loinc", LOINC)
        # g.bind("atc", ATC)
        # g.bind("rxnorm", RXNORM)
        # g.bind("ucum", UCUM)
        # g.bind("mesh", MESH)
        # g.bind("omop_ext", OMOP_EXT)
    g.graph(identifier=URIRef(default_graph_identifier))
    return g


def run_query(query: str) -> dict[str, Any]:
    """Function to run a SPARQL query against a remote endpoint"""
    import time
    start = time.time()
    query_endpoint.setQuery(query)
    result = query_endpoint.query().convert()
    duration = time.time() - start
    if duration > 1.0:  # Log queries taking more than 1 second
        logging.warning(f"[TIMING] SPARQL query took {duration:.2f}s")
    return result


def get_cohorts_metadata_query() -> str:
    """DEPRECATED: This old combined query has been replaced by two separate queries.
    Use get_studies_metadata_query() and get_variables_metadata_query() instead.
    This function is kept for backwards compatibility but may be removed in future versions."""
    query = f"""
PREFIX cmeo: <https://w3id.org/CMEO/>
PREFIX obi: <http://purl.obolibrary.org/obo/obi.owl/>
PREFIX bfo: <http://purl.obolibrary.org/obo/bfo.owl/>
PREFIX ro: <http://purl.obolibrary.org/obo/ro.owl/>
PREFIX iao: <http://purl.obolibrary.org/obo/iao.owl/>
PREFIX sio: <http://semanticscience.org/ontology/sio/v1.59/sio-release.owl#>
PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX dc: <http://purl.org/dc/elements/1.1/>
PREFIX icare: <{ICARE}>

SELECT DISTINCT ?cohortId ?cohortInstitution ?cohortEmail ?study_type ?study_participants ?study_duration ?study_ongoing ?study_population ?study_objective ?primary_outcome_spec ?secondary_outcome_spec ?morbidity ?study_start ?study_end ?male_percentage ?female_percentage ?administrator ?administrator_email ?study_contact_person ?study_contact_person_email ?references ?population_location ?language ?data_collection_frequency ?interventions ?sex_inclusion ?health_status_inclusion ?clinically_relevant_exposure_inclusion ?age_group_inclusion ?bmi_range_inclusion ?ethnicity_inclusion ?family_status_inclusion ?hospital_patient_inclusion ?use_of_medication_inclusion ?health_status_exclusion ?bmi_range_exclusion ?limited_life_expectancy_exclusion ?need_for_surgery_exclusion ?surgical_procedure_history_exclusion ?clinically_relevant_exposure_exclusion
    ?variable ?varName ?varLabel ?varType ?index ?count ?na ?max ?min ?units ?formula ?definition
    ?omopDomain ?conceptId ?conceptCode ?conceptName ?omopId ?mappedId ?mappedLabel ?visits ?categoryValue ?categoryLabel ?categoryConceptId ?categoryMappedId ?categoryMappedLabel
WHERE {{
    GRAPH <https://w3id.org/CMEO/graph/studies_metadata> {{
        ?study_design_execution a obi:study_design_execution ;
            dc:identifier ?cohortId .
        
        # Get institute/organization information  
        OPTIONAL {{
            ?study_design_execution ro:has_participant ?institute_entity .
            ?institute_entity a obi:organization ;
                cmeo:has_value ?cohortInstitution .
        }}
        
        # Get study type from descriptor
        OPTIONAL {{
            ?study_design_execution ro:concretizes ?study_design .
            ?study_design sio:is_described_by ?study_type_entity .
            ?study_type_entity a sio:study_descriptor ;
                cmeo:has_value ?study_type .
        }}
        
        # Get study objective
        OPTIONAL {{
            ?study_design_execution ro:concretizes ?study_design .
            ?study_design ro:has_part ?protocol .
            ?protocol ro:has_part ?study_objective_entity .
            ?study_objective_entity a obi:objective_specification ;
                cmeo:has_value ?study_objective .
        }}
        
        # Get number of participants
        OPTIONAL {{
            ?protocol ro:has_part ?number_of_participants_entity .
            ?number_of_participants_entity a cmeo:number_of_participants ;
                cmeo:has_value ?study_participants .
        }}
        
        # Get timing information
        OPTIONAL {{
            ?study_design_execution iao:has_time_stamp ?start_date_entity .
            ?start_date_entity a cmeo:start_time ;
                cmeo:has_value ?study_start .
        }}
        
        OPTIONAL {{
            ?study_design_execution iao:has_time_stamp ?end_date_entity .
            ?end_date_entity a cmeo:end_time ;
                cmeo:has_value ?study_end .
        }}
        
        OPTIONAL {{
            ?study_design_execution ro:has_characteristic ?ongoing_entity .
            ?ongoing_entity a cmeo:ongoing ;
                cmeo:has_value ?study_ongoing .
        }}
        
        # Get outcome specifications (direct from protocol, not nested)
        OPTIONAL {{
            ?protocol ro:has_part ?primary_outcome_spec_entity .
            ?primary_outcome_spec_entity a cmeo:primary_outcome_specification ;
                cmeo:has_value ?primary_outcome_spec .
        }}
        
        OPTIONAL {{
            ?protocol ro:has_part ?secondary_outcome_spec_entity .
            ?secondary_outcome_spec_entity a cmeo:secondary_outcome_specification ;
                cmeo:has_value ?secondary_outcome_spec .
        }}
        
        # Get morbidity information
        OPTIONAL {{
            ?protocol ro:has_part ?morbidity_entity .
            ?morbidity_entity a obi:morbidity ;
                cmeo:has_value ?morbidity .
        }}
        
        # Get eligibility criteria and demographics
        OPTIONAL {{
            ?protocol ro:has_part ?eligibility .
            ?eligibility a obi:eligibility_criterion .
            
            # Male/female percentages
            OPTIONAL {{
                ?eligibility ro:has_part ?male_percentage_entity .
                ?male_percentage_entity a cmeo:male_percentage ;
                    cmeo:has_value ?male_percentage .
            }}
            
            OPTIONAL {{
                ?eligibility ro:has_part ?female_percentage_entity .
                ?female_percentage_entity a cmeo:female_percentage ;
                    cmeo:has_value ?female_percentage .
            }}
        }}
        
        # Get age distribution
        OPTIONAL {{
            ?study_design_execution ro:has_characteristic ?age_distribution_entity .
            ?age_distribution_entity a obi:age_distribution ;
                cmeo:has_value ?age_distribution .
        }}
        
        # Get population location
        OPTIONAL {{
            ?study_design_execution ro:has_characteristic ?population_location_entity .
            ?population_location_entity a bfo:site ;
                cmeo:has_value ?population_location .
        }}
        
        # Get language (direct property)
        OPTIONAL {{
            ?study_design_execution dc:language ?language .
        }}
        
        # Get contact information (simplified - direct participants)
        OPTIONAL {{
            ?study_design_execution ro:has_participant ?study_contact_person_entity .
            ?study_contact_person_entity a cmeo:homo_sapiens ;
                cmeo:has_value ?study_contact_person .
        }}
        
        OPTIONAL {{
            ?study_design_execution ro:has_participant ?administrator_entity .
            ?administrator_entity a cmeo:homo_sapiens ;
                cmeo:has_value ?administrator .
        }}
    }}
    
    OPTIONAL {{
        GRAPH ?cohortGraph {{
            ?cohort icare:hasVariable ?variable .
            ?variable dc:identifier ?varName ;
                rdfs:label ?varLabel ;
                icare:varType ?varType ;
                icare:index ?index .
            OPTIONAL {{ ?variable icare:count ?count . }}
            OPTIONAL {{ ?variable icare:na ?na . }}
            OPTIONAL {{ ?variable icare:max ?max . }}
            OPTIONAL {{ ?variable icare:min ?min . }}
            OPTIONAL {{ ?variable icare:units ?units . }}
            OPTIONAL {{ ?variable icare:formula ?formula . }}
            OPTIONAL {{ ?variable icare:definition ?definition . }}
            OPTIONAL {{ ?variable icare:omopDomain ?omopDomain . }}
            OPTIONAL {{ ?variable icare:conceptId ?conceptId . }}
            OPTIONAL {{ ?variable icare:conceptCode ?conceptCode . }}
            OPTIONAL {{ ?variable icare:conceptName ?conceptName . }}
            OPTIONAL {{ ?variable icare:omopId ?omopId . }}
            OPTIONAL {{ ?variable icare:mappedId ?mappedId . }}
            OPTIONAL {{ ?variable icare:mappedLabel ?mappedLabel . }}
            OPTIONAL {{ ?variable icare:visits ?visits . }}
            
            OPTIONAL {{
                ?variable icare:categories ?category .
                ?category rdf:value ?categoryValue ;
                    rdfs:label ?categoryLabel .
                OPTIONAL {{ ?category icare:conceptId ?categoryConceptId . }}
                OPTIONAL {{ ?category icare:mappedId ?categoryMappedId . }}
                OPTIONAL {{ ?category icare:mappedLabel ?categoryMappedLabel . }}
            }}
        }}
    }}
}}
ORDER BY ?cohortId ?index ?categoryValue"""
    return query


# TODO: Utility to get value or None if key is missing or value is empty string
def get_value(key: str, row: dict[str, Any]) -> str:
    """Safely get a value from a SPARQL result row.
    
    Args:
        key: The key to look for in the row
        row: The SPARQL result row dictionary
        
    Returns:
        The string value if found, empty string otherwise
    """
    try:
        if key in row and row[key]["value"]:
            return str(row[key]["value"])
        return ""
    except (KeyError, TypeError):
        return ""


def get_int_value(key: str, row: dict[str, Any]) -> int | None:
    """Safely get an integer value from a SPARQL result row.
    
    Args:
        key: The key to look for in the row
        row: The SPARQL result row dictionary
        
    Returns:
        The integer value if found and valid, None otherwise
    """
    try:
        if key in row and row[key]["value"]:
            return int(row[key]["value"])
        return None
    except (KeyError, TypeError, ValueError):
        return None


def get_bool_value(key: str, row: dict[str, Any]) -> bool:
    """Safely get a boolean value from a SPARQL result row.
    
    Args:
        key: The key to look for in the row
        row: The SPARQL result row dictionary
        
    Returns:
        True if the value is 'true' (case insensitive), False otherwise
    """
    try:
        if key in row and row[key]["value"]:
            return str(row[key]["value"]).lower() == "true"
        return False
    except (KeyError, TypeError):
        return False


def get_curie_value(key: str, row: dict[str, Any]) -> str | None:
    """Safely get a CURIE value from a SPARQL result row.
    
    Args:
        key: The key to look for in the row
        row: The SPARQL result row dictionary
        
    Returns:
        The compressed CURIE value if found and valid, None otherwise
    """
    try:
        value = get_value(key, row)
        if value:
            return curie_converter.compress(value)
        return None
    except Exception:
        return None


def get_studies_metadata_query() -> str:
    """Get SPARQL query for retrieving studies/cohorts metadata (from sparql_queries.txt)."""
    # Load the first query from CohortVarLinker/queries/sparql_queries.txt (lines 3-291)
    import os
    query_file = os.path.join(os.path.dirname(__file__), '..', 'CohortVarLinker', 'queries', 'sparql_queries.txt')
    with open(query_file, 'r') as f:
        lines = f.readlines()
        # Extract lines 3-291 (study metadata query)
        # Lines 1-2 are comments, so we skip them
        query = ''.join(lines[2:290])  # 0-indexed, so lines[2:290] = lines 3-290
    return query


def get_variables_metadata_query() -> str:
    """Get SPARQL query for retrieving variables metadata (from sparql_queries.txt)."""
    # Load the second query from CohortVarLinker/queries/sparql_queries.txt (lines 298-542)
    import os
    query_file = os.path.join(os.path.dirname(__file__), '..', 'CohortVarLinker', 'queries', 'sparql_queries.txt')
    with open(query_file, 'r') as f:
        lines = f.readlines()
        # Extract lines 298-542 (variables metadata query)
        # Line 295 says "# Query to Retrieve Variables Metadata from All studies"
        # Line 296 says "it takes 70 seconds with oxigraph"
        # Line 297 is blank
        # Line 298 starts with PREFIX
        query = ''.join(lines[297:542])  # 0-indexed
    return query


def retrieve_cohorts_metadata(user_email: str, include_sparql_metadata: bool = False) -> dict[str, Cohort] | dict:
    """Get all cohorts metadata from the SPARQL endpoint using two separate queries.
    
    This new implementation uses two separate queries instead of one large combined query:
    1. First query: Retrieves study/cohort metadata from studies_metadata graph
    2. Second query: Retrieves variables metadata from individual study graphs
    3. Merges results to create complete Cohort objects
    
    Args:
        user_email: Email of the user requesting the data
        include_sparql_metadata: If True, returns dict with cohorts and metadata
    """
    import time
    start_time = time.time()
    
    # ===== STEP 1: Execute Studies Metadata Query =====
    studies_query_start = time.time()
    studies_results = run_query(get_studies_metadata_query())["results"]["bindings"]
    studies_query_duration = time.time() - studies_query_start
    logging.info(f"Studies metadata query: {studies_query_duration:.2f}s, {len(studies_results)} results")
    
    # ===== STEP 2: Execute Variables Metadata Query =====
    variables_query_start = time.time()
    variables_results = run_query(get_variables_metadata_query())["results"]["bindings"]
    variables_query_duration = time.time() - variables_query_start
    logging.info(f"Variables metadata query: {variables_query_duration:.2f}s, {len(variables_results)} results")
    
    total_query_duration = studies_query_duration + variables_query_duration
    
    # ===== STEP 3: Process Studies Metadata =====
    cohorts = {}
    
    for row in studies_results:
        try:
            cohort_id = str(row["cohortId"]["value"])
            
            if cohort_id not in cohorts:
                cohort = Cohort(
                    cohort_id=get_value("cohortId", row),
                    institution=get_value("cohortInstitution", row),
                    study_type=get_value("study_type", row),
                    study_participants=get_value("study_participants", row),
                    study_duration=get_value("duration", row),  # Note: new query uses "duration" not "study_duration"
                    study_ongoing=get_value("study_ongoing", row),
                    study_population=get_value("study_population", row),  # May not be in new query
                    study_objective=get_value("study_objective", row),
                    primary_outcome_spec=get_value("primary_outcome_spec", row),
                    secondary_outcome_spec=get_value("secondary_outcome_spec", row),
                    morbidity=get_value("morbidity", row),
                    study_start=get_value("study_start", row),
                    study_end=get_value("study_end", row),
                    male_percentage=None,  # Not in new query structure
                    female_percentage=None,  # Not in new query structure
                    # Contact information fields
                    administrator=get_value("administrator", row),
                    administrator_email=get_value("administrator_email", row),
                    study_contact_person=get_value("study_contact_person", row),
                    study_contact_person_email=get_value("study_contact_person_email", row),
                    references=[],
                    # Additional metadata fields
                    population_location=get_value("population_location", row),
                    language=get_value("language", row),
                    data_collection_frequency=get_value("data_collection_frequency", row),
                    interventions=get_value("interventions", row),
                    # Inclusion/Exclusion criteria - new query structure
                    sex_inclusion=get_value("inclusion_labels", row),  # Aggregated in new query
                    health_status_inclusion=get_value("inclusion_values", row),  # Aggregated
                    clinically_relevant_exposure_inclusion="",
                    age_group_inclusion="",
                    bmi_range_inclusion="",
                    ethnicity_inclusion="",
                    family_status_inclusion="",
                    hospital_patient_inclusion="",
                    use_of_medication_inclusion="",
                    # Exclusion criteria fields
                    health_status_exclusion=get_value("exclusion_labels", row),  # Aggregated
                    bmi_range_exclusion=get_value("exclusion_values", row),  # Aggregated
                    limited_life_expectancy_exclusion="",
                    need_for_surgery_exclusion="",
                    surgical_procedure_history_exclusion="",
                    clinically_relevant_exposure_exclusion="",
                    variables={},
                    can_edit=user_email in settings.admins_list,
                    physical_dictionary_exists=False
                )
                cohorts[cohort_id] = cohort
                
                # Check if physical dictionary file exists
                try:
                    if cohorts[cohort_id].metadata_filepath:
                        cohorts[cohort_id].physical_dictionary_exists = True
                except FileNotFoundError:
                    cohorts[cohort_id].physical_dictionary_exists = False
                    
        except Exception as e:
            logging.warning(f"Error processing study row {row}: {e}")
    
    # ===== STEP 4: Process Variables Metadata =====
    # Group variables by study
    for row in variables_results:
        try:
            # Extract study name from the query result
            study_name = get_value("study_name", row)
            var_name = get_value("var_name", row)
            
            # Match study_name to cohort_id (they should be the same or similar)
            # Find the matching cohort
            cohort_id = None
            for cid in cohorts.keys():
                if cid.lower() == study_name.lower() or study_name.lower() in cid.lower():
                    cohort_id = cid
                    break
            
            if not cohort_id:
                # If we can't find a match, use study_name as cohort_id
                cohort_id = study_name
                
            # If cohort doesn't exist yet (shouldn't happen), skip or create skeleton
            if cohort_id not in cohorts:
                logging.warning(f"Variable for unknown cohort: {cohort_id}")
                continue
            
            # Add variable to cohort
            if var_name and var_name not in cohorts[cohort_id].variables:
                # Parse categorical values (format: "value1=label1|value2=label2")
                categories = []
                categorical_values_str = get_value("categorical_values", row)
                if categorical_values_str:
                    pairs = categorical_values_str.split("|")
                    category_codes_list = get_value("category_concept_codes", row).split("|") if get_value("category_concept_codes", row) else []
                    category_labels_list = get_value("category_concept_label", row).split("|") if get_value("category_concept_label", row) else []
                    category_omop_list = get_value("category_omop_id", row).split("|") if get_value("category_omop_id", row) else []
                    
                    for i, pair in enumerate(pairs):
                        if "=" in pair:
                            value, label = pair.split("=", 1)
                            categories.append(VariableCategory(
                                value=value.strip(),
                                label=label.strip(),
                                concept_id=category_codes_list[i] if i < len(category_codes_list) else None,
                                mapped_id=None,
                                mapped_label=category_labels_list[i] if i < len(category_labels_list) else None,
                            ))
                
                # Parse concept codes and labels (format: "code1 || code2 || code3")
                concept_codes_str = get_value("concept_codes", row)
                concept_labels_str = get_value("concept_labels", row)
                concept_codes_list = concept_codes_str.split(" || ") if concept_codes_str else []
                concept_labels_list = concept_labels_str.split(" || ") if concept_labels_str else []
                
                cohorts[cohort_id].variables[var_name] = CohortVariable(
                    var_name=var_name,
                    var_label=get_value("var_label", row),
                    var_type=get_value("varType", row),
                    count=get_int_value("count_value", row) or 0,
                    max=get_value("maximum_value", row),
                    min=get_value("minimum_value", row),
                    units=get_value("unit_value", row),
                    visits=get_value("visit", row),
                    formula=get_value("formula_value", row),
                    definition="",  # Not in new query
                    concept_id=concept_codes_list[0] if concept_codes_list else None,
                    concept_code=concept_codes_list[0] if concept_codes_list else None,
                    concept_name=concept_labels_list[0] if concept_labels_list else None,
                    omop_id=get_value("concept_omop_id", row),
                    mapped_id=None,  # Not clear in new query
                    mapped_label=None,  # Not clear in new query
                    omop_domain=get_value("omopDomain", row),
                    index=None,  # Not in new query
                    na=0,  # Not in new query
                    categories=categories
                )
                
        except Exception as e:
            logging.warning(f"Error processing variable row: {e}")
    
    # ===== STEP 5: Separate cohorts with and without variables =====
    cohorts_with_variables = {k: v for k, v in cohorts.items() if v.variables}
    cohorts_without_variables = {k: v for k, v in cohorts.items() if not v.variables}
    
    # Merge with variables first (so they appear at top)
    cohorts = {**cohorts_with_variables, **cohorts_without_variables}
    
    # Log timing information
    end_time = time.time()
    total_duration = end_time - start_time
    processing_duration = total_duration - total_query_duration
    logging.info(f"Total retrieval time: {total_duration:.2f}s (Queries: {total_query_duration:.2f}s, Processing: {processing_duration:.2f}s)")
    
    # Return with metadata if requested
    if include_sparql_metadata:
        return {
            "cohorts": cohorts,
            "sparql_metadata": {
                "row_count": len(studies_results) + len(variables_results),
                "studies_count": len(studies_results),
                "variables_count": len(variables_results),
                "query_duration_ms": round(total_query_duration * 1000),
                "processing_duration_ms": round(processing_duration * 1000),
                "total_duration_ms": round(total_duration * 1000)
            }
        }
    
    return cohorts

